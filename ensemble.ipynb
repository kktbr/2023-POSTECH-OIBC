{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.font_manager as fm\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "import requests\n",
    "import pytz\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "from scipy.stats import skew, kurtosis\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, VotingRegressor, StackingRegressor, AdaBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression, TheilSenRegressor, HuberRegressor\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/USER/Desktop/OIBC2023_data/OIBC2023_data/{}\"\n",
    "\n",
    "incentive = pd.read_csv(path.format('incentive.csv'))\n",
    "pred = pd.read_csv(path.format('pred.csv'))\n",
    "weather_actual = pd.read_csv(path.format('weather_actual.csv'))\n",
    "weather_forecast = pd.read_csv(path.format('weather_forecast.csv'))\n",
    "gens = pd.read_csv(path.format('gens.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "incentive['time'] = pd.to_datetime(incentive['time'])\n",
    "pred['time'] = pd.to_datetime(pred['time'])\n",
    "weather_actual['time'] = pd.to_datetime(weather_actual['time'])\n",
    "weather_forecast['time'] = pd.to_datetime(weather_forecast['time'])\n",
    "gens['time'] = pd.to_datetime(gens['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(prediction, wf):\n",
    "    df1 = prediction[prediction['round'] == 1]\n",
    "    df2 = prediction[prediction['round'] == 2]\n",
    "\n",
    "    ##########\n",
    "    df1 = df1.pivot(index='time', columns='model_id', values='amount').reset_index()\n",
    "    df2 = df2.pivot(index='time', columns='model_id', values='amount').reset_index()\n",
    "    print(df1)\n",
    "    print(df2)\n",
    "\n",
    "    df1.columns = ['time','model1', 'model2', 'model3', 'model4', 'model5']\n",
    "    df2.columns = ['time','model1', 'model2', 'model3', 'model4', 'model5']\n",
    "\n",
    "  \n",
    "    wf_1 = wf[wf['round'] == 1]\n",
    "    wf_2 = wf[wf['round'] == 2]\n",
    "    \n",
    "    \n",
    "    #날씨와 예측량 병합\n",
    "    a = df1.merge(wf_1, on='time').set_index('time')\n",
    "    b = df2.merge(wf_2, on='time').set_index('time')\n",
    "    print(a)\n",
    "    print(b)\n",
    "\n",
    "    a = a[['cloud', 'temp', 'humidity', 'ground_press', 'wind_speed',\n",
    "       'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx', 'azimuth',\n",
    "       'elevation','model1', 'model2', 'model3', 'model4', 'model5']]\n",
    "\n",
    "    b = b[['cloud', 'temp', 'humidity', 'ground_press', 'wind_speed',\n",
    "       'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx', 'azimuth',\n",
    "       'elevation','model1', 'model2', 'model3', 'model4', 'model5']]\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id                      time    0    1    2    3    4\n",
      "0        2022-06-19 01:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "1        2022-06-19 02:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "2        2022-06-19 03:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "3        2022-06-19 04:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "4        2022-06-19 05:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "...                            ...  ...  ...  ...  ...  ...\n",
      "11611    2023-10-15 20:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "11612    2023-10-15 21:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "11613    2023-10-15 22:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "11614    2023-10-15 23:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "11615    2023-10-16 00:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[11616 rows x 6 columns]\n",
      "model_id                      time    0    1    2    3    4\n",
      "0        2022-06-19 01:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "1        2022-06-19 02:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "2        2022-06-19 03:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "3        2022-06-19 04:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "4        2022-06-19 05:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "...                            ...  ...  ...  ...  ...  ...\n",
      "11587    2023-10-15 20:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "11588    2023-10-15 21:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "11589    2023-10-15 22:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "11590    2023-10-15 23:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "11591    2023-10-16 00:00:00+09:00  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[11592 rows x 6 columns]\n",
      "                           model1  model2  model3  model4  model5  round  \\\n",
      "time                                                                       \n",
      "2022-06-19 01:00:00+09:00     0.0     0.0     0.0     0.0     0.0      1   \n",
      "2022-06-19 02:00:00+09:00     0.0     0.0     0.0     0.0     0.0      1   \n",
      "2022-06-19 03:00:00+09:00     0.0     0.0     0.0     0.0     0.0      1   \n",
      "2022-06-19 04:00:00+09:00     0.0     0.0     0.0     0.0     0.0      1   \n",
      "2022-06-19 05:00:00+09:00     0.0     0.0     0.0     0.0     0.0      1   \n",
      "...                           ...     ...     ...     ...     ...    ...   \n",
      "2023-10-15 20:00:00+09:00     0.0     0.0     0.0     0.0     0.0      1   \n",
      "2023-10-15 21:00:00+09:00     0.0     0.0     0.0     0.0     0.0      1   \n",
      "2023-10-15 22:00:00+09:00     0.0     0.0     0.0     0.0     0.0      1   \n",
      "2023-10-15 23:00:00+09:00     0.0     0.0     0.0     0.0     0.0      1   \n",
      "2023-10-16 00:00:00+09:00     0.0     0.0     0.0     0.0     0.0      1   \n",
      "\n",
      "                           cloud   temp  humidity  ground_press  wind_speed  \\\n",
      "time                                                                          \n",
      "2022-06-19 01:00:00+09:00    6.0  20.03      93.0        1009.0        3.01   \n",
      "2022-06-19 02:00:00+09:00    7.0  19.88      95.0        1009.0        3.16   \n",
      "2022-06-19 03:00:00+09:00   17.0  19.99      96.0        1008.0        2.92   \n",
      "2022-06-19 04:00:00+09:00  100.0  20.19      96.0        1008.0        2.79   \n",
      "2022-06-19 05:00:00+09:00  100.0  20.34      95.0        1008.0        2.74   \n",
      "...                          ...    ...       ...           ...         ...   \n",
      "2023-10-15 20:00:00+09:00    0.0  18.50      72.0        1015.0        5.49   \n",
      "2023-10-15 21:00:00+09:00    0.0  18.60      73.0        1015.0        5.36   \n",
      "2023-10-15 22:00:00+09:00    0.0  18.64      73.0        1015.0        5.77   \n",
      "2023-10-15 23:00:00+09:00    0.0  18.70      70.0        1015.0        5.91   \n",
      "2023-10-16 00:00:00+09:00    0.0  18.75      70.0        1015.0        6.07   \n",
      "\n",
      "                           wind_dir  rain  snow  dew_point      vis  uv_idx  \\\n",
      "time                                                                          \n",
      "2022-06-19 01:00:00+09:00     162.0   0.0   0.0    18.3333  16.0934     0.0   \n",
      "2022-06-19 02:00:00+09:00     159.0   0.0   0.0    18.3333  16.0934     0.0   \n",
      "2022-06-19 03:00:00+09:00     161.0   0.0   0.0    18.3333  16.0934     0.0   \n",
      "2022-06-19 04:00:00+09:00     157.0   0.0   0.0    17.7778  16.0934     0.0   \n",
      "2022-06-19 05:00:00+09:00     156.0   0.0   0.0    18.3333  16.0934     0.0   \n",
      "...                             ...   ...   ...        ...      ...     ...   \n",
      "2023-10-15 20:00:00+09:00     325.0   0.0   0.0    12.7778  16.0934     0.0   \n",
      "2023-10-15 21:00:00+09:00     313.0   0.0   0.0    12.7778  16.0934     0.0   \n",
      "2023-10-15 22:00:00+09:00     306.0   0.0   0.0    12.7778  16.0934     0.0   \n",
      "2023-10-15 23:00:00+09:00     302.0   0.0   0.0    12.2222  16.0934     0.0   \n",
      "2023-10-16 00:00:00+09:00     297.0   0.0   0.0    12.2222  16.0934     0.0   \n",
      "\n",
      "                             azimuth  elevation  \n",
      "time                                             \n",
      "2022-06-19 01:00:00+09:00    6.70428   -31.5296  \n",
      "2022-06-19 02:00:00+09:00   22.19640   -28.4404  \n",
      "2022-06-19 03:00:00+09:00   35.91940   -22.4374  \n",
      "2022-06-19 04:00:00+09:00   47.55770   -14.2214  \n",
      "2022-06-19 05:00:00+09:00   57.37820    -4.4447  \n",
      "...                              ...        ...  \n",
      "2023-10-15 20:00:00+09:00  277.46500   -25.3792  \n",
      "2023-10-15 21:00:00+09:00  287.67900   -37.4097  \n",
      "2023-10-15 22:00:00+09:00  301.00700   -48.6552  \n",
      "2023-10-15 23:00:00+09:00  320.43400   -58.0565  \n",
      "2023-10-16 00:00:00+09:00  349.06500   -63.4218  \n",
      "\n",
      "[11616 rows x 19 columns]\n",
      "                           model1  model2  model3  model4  model5  round  \\\n",
      "time                                                                       \n",
      "2022-06-19 01:00:00+09:00     0.0     0.0     0.0     0.0     0.0      2   \n",
      "2022-06-19 02:00:00+09:00     0.0     0.0     0.0     0.0     0.0      2   \n",
      "2022-06-19 03:00:00+09:00     0.0     0.0     0.0     0.0     0.0      2   \n",
      "2022-06-19 04:00:00+09:00     0.0     0.0     0.0     0.0     0.0      2   \n",
      "2022-06-19 05:00:00+09:00     0.0     0.0     0.0     0.0     0.0      2   \n",
      "...                           ...     ...     ...     ...     ...    ...   \n",
      "2023-10-15 20:00:00+09:00     0.0     0.0     0.0     0.0     0.0      2   \n",
      "2023-10-15 21:00:00+09:00     0.0     0.0     0.0     0.0     0.0      2   \n",
      "2023-10-15 22:00:00+09:00     0.0     0.0     0.0     0.0     0.0      2   \n",
      "2023-10-15 23:00:00+09:00     0.0     0.0     0.0     0.0     0.0      2   \n",
      "2023-10-16 00:00:00+09:00     0.0     0.0     0.0     0.0     0.0      2   \n",
      "\n",
      "                           cloud   temp  humidity  ground_press  wind_speed  \\\n",
      "time                                                                          \n",
      "2022-06-19 01:00:00+09:00    7.0  19.95      94.0        1009.0        2.65   \n",
      "2022-06-19 02:00:00+09:00   24.0  20.15      94.0        1009.0        2.55   \n",
      "2022-06-19 03:00:00+09:00   36.0  20.23      95.0        1009.0        2.60   \n",
      "2022-06-19 04:00:00+09:00   95.0  20.35      95.0        1008.0        2.84   \n",
      "2022-06-19 05:00:00+09:00   97.0  20.43      96.0        1009.0        3.06   \n",
      "...                          ...    ...       ...           ...         ...   \n",
      "2023-10-15 20:00:00+09:00    0.0  18.51      69.0        1015.0        5.56   \n",
      "2023-10-15 21:00:00+09:00    0.0  18.59      70.0        1015.0        5.25   \n",
      "2023-10-15 22:00:00+09:00    0.0  18.68      69.0        1015.0        5.58   \n",
      "2023-10-15 23:00:00+09:00    0.0  18.77      66.0        1015.0        5.75   \n",
      "2023-10-16 00:00:00+09:00    0.0  18.71      66.0        1015.0        5.85   \n",
      "\n",
      "                           wind_dir  rain  snow  dew_point      vis  uv_idx  \\\n",
      "time                                                                          \n",
      "2022-06-19 01:00:00+09:00     152.0   0.0   0.0    18.3333  16.0934     0.0   \n",
      "2022-06-19 02:00:00+09:00     148.0   0.0   0.0    18.3333  16.0934     0.0   \n",
      "2022-06-19 03:00:00+09:00     158.0   0.0   0.0    18.3333  16.0934     0.0   \n",
      "2022-06-19 04:00:00+09:00     164.0   0.0   0.0    17.7778  16.0934     0.0   \n",
      "2022-06-19 05:00:00+09:00     163.0   0.0   0.0    18.3333  16.0934     0.0   \n",
      "...                             ...   ...   ...        ...      ...     ...   \n",
      "2023-10-15 20:00:00+09:00     328.0   0.0   0.0    12.7778  16.0934     0.0   \n",
      "2023-10-15 21:00:00+09:00     317.0   0.0   0.0    12.7778  16.0934     0.0   \n",
      "2023-10-15 22:00:00+09:00     310.0   0.0   0.0    12.7778  16.0934     0.0   \n",
      "2023-10-15 23:00:00+09:00     306.0   0.0   0.0    12.2222  16.0934     0.0   \n",
      "2023-10-16 00:00:00+09:00     306.0   0.0   0.0    12.2222  16.0934     0.0   \n",
      "\n",
      "                             azimuth  elevation  \n",
      "time                                             \n",
      "2022-06-19 01:00:00+09:00    6.70428   -31.5296  \n",
      "2022-06-19 02:00:00+09:00   22.19640   -28.4404  \n",
      "2022-06-19 03:00:00+09:00   35.91940   -22.4374  \n",
      "2022-06-19 04:00:00+09:00   47.55770   -14.2214  \n",
      "2022-06-19 05:00:00+09:00   57.37820    -4.4447  \n",
      "...                              ...        ...  \n",
      "2023-10-15 20:00:00+09:00  277.46500   -25.3792  \n",
      "2023-10-15 21:00:00+09:00  287.67900   -37.4097  \n",
      "2023-10-15 22:00:00+09:00  301.00700   -48.6552  \n",
      "2023-10-15 23:00:00+09:00  320.43400   -58.0565  \n",
      "2023-10-16 00:00:00+09:00  349.06500   -63.4218  \n",
      "\n",
      "[11568 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "round1, round2 = preprocessing(pred, weather_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cloud</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ground_press</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>...</th>\n",
       "      <th>uv_idx</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>elevation</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>model5</th>\n",
       "      <th>pred_mean</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-19 01:00:00+09:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.03</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>3.01</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.3333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.70428</td>\n",
       "      <td>-31.5296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-19 02:00:00+09:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.88</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.3333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.19640</td>\n",
       "      <td>-28.4404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-19 03:00:00+09:00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.99</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.3333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.91940</td>\n",
       "      <td>-22.4374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-19 04:00:00+09:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.19</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.7778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.55770</td>\n",
       "      <td>-14.2214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-19 05:00:00+09:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.34</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.3333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.37820</td>\n",
       "      <td>-4.4447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11611</th>\n",
       "      <td>2023-10-15 20:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.50</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>5.49</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.7778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.46500</td>\n",
       "      <td>-25.3792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11612</th>\n",
       "      <td>2023-10-15 21:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.60</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>313.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.7778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.67900</td>\n",
       "      <td>-37.4097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11613</th>\n",
       "      <td>2023-10-15 22:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.64</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>5.77</td>\n",
       "      <td>306.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.7778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.00700</td>\n",
       "      <td>-48.6552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11614</th>\n",
       "      <td>2023-10-15 23:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.70</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>5.91</td>\n",
       "      <td>302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.43400</td>\n",
       "      <td>-58.0565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11615</th>\n",
       "      <td>2023-10-16 00:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>6.07</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349.06500</td>\n",
       "      <td>-63.4218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11616 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           time  cloud   temp  humidity  ground_press  \\\n",
       "0     2022-06-19 01:00:00+09:00    6.0  20.03      93.0        1009.0   \n",
       "1     2022-06-19 02:00:00+09:00    7.0  19.88      95.0        1009.0   \n",
       "2     2022-06-19 03:00:00+09:00   17.0  19.99      96.0        1008.0   \n",
       "3     2022-06-19 04:00:00+09:00  100.0  20.19      96.0        1008.0   \n",
       "4     2022-06-19 05:00:00+09:00  100.0  20.34      95.0        1008.0   \n",
       "...                         ...    ...    ...       ...           ...   \n",
       "11611 2023-10-15 20:00:00+09:00    0.0  18.50      72.0        1015.0   \n",
       "11612 2023-10-15 21:00:00+09:00    0.0  18.60      73.0        1015.0   \n",
       "11613 2023-10-15 22:00:00+09:00    0.0  18.64      73.0        1015.0   \n",
       "11614 2023-10-15 23:00:00+09:00    0.0  18.70      70.0        1015.0   \n",
       "11615 2023-10-16 00:00:00+09:00    0.0  18.75      70.0        1015.0   \n",
       "\n",
       "       wind_speed  wind_dir  rain  snow  dew_point  ...  uv_idx    azimuth  \\\n",
       "0            3.01     162.0   0.0   0.0    18.3333  ...     0.0    6.70428   \n",
       "1            3.16     159.0   0.0   0.0    18.3333  ...     0.0   22.19640   \n",
       "2            2.92     161.0   0.0   0.0    18.3333  ...     0.0   35.91940   \n",
       "3            2.79     157.0   0.0   0.0    17.7778  ...     0.0   47.55770   \n",
       "4            2.74     156.0   0.0   0.0    18.3333  ...     0.0   57.37820   \n",
       "...           ...       ...   ...   ...        ...  ...     ...        ...   \n",
       "11611        5.49     325.0   0.0   0.0    12.7778  ...     0.0  277.46500   \n",
       "11612        5.36     313.0   0.0   0.0    12.7778  ...     0.0  287.67900   \n",
       "11613        5.77     306.0   0.0   0.0    12.7778  ...     0.0  301.00700   \n",
       "11614        5.91     302.0   0.0   0.0    12.2222  ...     0.0  320.43400   \n",
       "11615        6.07     297.0   0.0   0.0    12.2222  ...     0.0  349.06500   \n",
       "\n",
       "       elevation  model1  model2  model3  model4  model5  pred_mean  real  \n",
       "0       -31.5296     0.0     0.0     0.0     0.0     0.0        0.0   0.0  \n",
       "1       -28.4404     0.0     0.0     0.0     0.0     0.0        0.0   0.0  \n",
       "2       -22.4374     0.0     0.0     0.0     0.0     0.0        0.0   0.0  \n",
       "3       -14.2214     0.0     0.0     0.0     0.0     0.0        0.0   0.0  \n",
       "4        -4.4447     0.0     0.0     0.0     0.0     0.0        0.0   0.0  \n",
       "...          ...     ...     ...     ...     ...     ...        ...   ...  \n",
       "11611   -25.3792     0.0     0.0     0.0     0.0     0.0        0.0   0.0  \n",
       "11612   -37.4097     0.0     0.0     0.0     0.0     0.0        0.0   0.0  \n",
       "11613   -48.6552     0.0     0.0     0.0     0.0     0.0        0.0   0.0  \n",
       "11614   -58.0565     0.0     0.0     0.0     0.0     0.0        0.0   0.0  \n",
       "11615   -63.4218     0.0     0.0     0.0     0.0     0.0        0.0   0.0  \n",
       "\n",
       "[11616 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round1['pred_mean'] = round1[['model1', 'model2', 'model3', 'model4', 'model5']].mean(axis=1)\n",
    "round2['pred_mean'] = round2[['model1', 'model2', 'model3', 'model4', 'model5']].mean(axis=1)\n",
    "\n",
    "round1 = pd.merge(round1, gens, on='time')\n",
    "round1.rename(columns = {'amount': 'real'}, inplace=True)\n",
    "round2 = pd.merge(round2, gens, on='time')\n",
    "round2.rename(columns = {'amount': 'real'}, inplace=True)\n",
    "\n",
    "round1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_pre_round1 = pd.read_csv(path.format('날씨예측값_round1.csv'))\n",
    "gens_pre_round1 = pd.read_csv(path.format('모델예측값_round1.csv'))\n",
    "weather_pre_round2 = pd.read_csv(path.format('날씨예측값_round2.csv'))\n",
    "gens_pre_round2 = pd.read_csv(path.format('모델예측값_round2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_time(df):\n",
    "    time = []\n",
    "    for _ in df['time']:\n",
    "        \n",
    "        utc_time_str = _\n",
    "        utc_time = datetime.strptime(utc_time_str, '%Y-%m-%dT%H:%M:%S%z')\n",
    "\n",
    "        korea_timezone = pytz.timezone('Asia/Seoul')\n",
    "        korea_time = utc_time.astimezone(korea_timezone)\n",
    "        time.append(korea_time.strftime('%Y-%m-%d %H:%M:%S%z'))\n",
    "    df['time'] = time\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_pre_round1 = change_time(weather_pre_round1)\n",
    "gens_pre_round1 = change_time(gens_pre_round1)\n",
    "weather_pre_round2 = change_time(weather_pre_round2)\n",
    "gens_pre_round2 = change_time(gens_pre_round2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_round1 = pd.merge(weather_pre_round1, gens_pre_round1, on='time').reset_index(drop=True)\n",
    "api_round2 = pd.merge(weather_pre_round2, gens_pre_round2, on='time').reset_index(drop=True)\n",
    "\n",
    "api_round1['time'] = pd.to_datetime(api_round1['time'])\n",
    "api_round2['time'] = pd.to_datetime(api_round2['time'])\n",
    "\n",
    "api_round1['pred_mean'] = api_round1[['model1', 'model2', 'model3', 'model4', 'model5']].mean(axis=1)\n",
    "api_round2['pred_mean'] = api_round2[['model1', 'model2', 'model3', 'model4', 'model5']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "round1_ = pd.concat([round1, api_round1], axis=0).reset_index(drop=True)\n",
    "round2_ = pd.concat([round2, api_round2], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_feature = ['cloud', 'temp', 'humidity', 'ground_press', 'wind_speed',\n",
    "       'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx', 'azimuth',\n",
    "       'elevation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_predict(r, round_num, date):\n",
    "    pred_result_list = []\n",
    "    fcst_list = []\n",
    "\n",
    "    bid_round = round_num\n",
    "    API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJTZ3FicHhyZVVMaGRtaWVuU1JxWWl4IiwiaWF0IjoxNjk4ODk2MTYxLCJleHAiOjE3MDAyMzMyMDAsInR5cGUiOiJhcGlfa2V5In0.I9OvmWqhDhf3ePv8t-hFFWwGCokcSbK7e8-fJfIZ5lU\"\n",
    "    weather_fcst = requests.get(f'https://research-api.solarkim.com/cmpt-2023/weathers-forecasts/{date}/{bid_round}', headers={\n",
    "                              'Authorization': f'Bearer {API_KEY}'\n",
    "                          }).json()\n",
    "    gen_fcst = requests.get(f'https://research-api.solarkim.com/cmpt-2023/gen-forecasts/{date}/{bid_round}', headers={\n",
    "                                'Authorization': f'Bearer {API_KEY}'\n",
    "                            }).json()\n",
    "    gen_fcst = pd.DataFrame(gen_fcst).set_index('time')\n",
    "    gen_fcst['time'] = gen_fcst.index\n",
    "    gen_fcst.index = range(0, 24)\n",
    "\n",
    "    fcst_list.append(pd.DataFrame(weather_fcst))\n",
    "    fcst_combined = pd.concat(fcst_list, ignore_index=True)\n",
    "    ###\n",
    "    time = []\n",
    "    for _ in fcst_combined['time']:\n",
    "      utc_time_str = _\n",
    "      utc_time = datetime.strptime(utc_time_str, '%Y-%m-%dT%H:%M:%S%z')\n",
    "\n",
    "      korea_timezone = pytz.timezone('Asia/Seoul')\n",
    "      korea_time = utc_time.astimezone(korea_timezone)\n",
    "      time.append(korea_time.strftime('%Y-%m-%d %H:%M:%S%z'))\n",
    "\n",
    "    fcst_combined['time'] = time\n",
    "    gen_fcst['time'] = time\n",
    "\n",
    "    fcst_combined['time'] = pd.to_datetime(fcst_combined['time'])\n",
    "    fcst_combined['hour'] = fcst_combined['time'].dt.hour\n",
    "\n",
    "    gen_fcst['time'] = pd.to_datetime(gen_fcst['time'])\n",
    "\n",
    "    api_merge = pd.merge(gen_fcst, fcst_combined, on='time')\n",
    "    api_merge['pred_mean'] = api_merge[['model1', 'model2', 'model3', 'model4', 'model5']].mean(axis=1)\n",
    "    ###\n",
    "    select_round = r ##############################\n",
    "    weather_merge = pd.concat([select_round, api_merge], axis=0).reset_index(drop=True)\n",
    "    #weather_merge = feature_engineering(weather_merge) #############\n",
    "    #print(weather_merge)########\n",
    "\n",
    "    df = weather_merge ##\n",
    "\n",
    "    #scale_col = ['cloud', 'temp', 'humidity', 'ground_press', 'wind_speed',\n",
    "   #'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx', 'azimuth',\n",
    "   #'elevation', 'feels_like', 'heat_index', 'wind_dir_rad', 'sun_uv_interaction', 'solar_radiation_morning', 'solar_radiation_afternoon', 'solar_radiation_evening']\n",
    "    scale_col = ['cloud', 'temp', 'humidity', 'ground_press', 'wind_speed',\n",
    "   'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx', 'azimuth',\n",
    "   'elevation']\n",
    "    scaler = StandardScaler()\n",
    "    df[scale_col] = scaler.fit_transform(df[scale_col])\n",
    "\n",
    "    Label1=np.column_stack([df['temp'], df['dew_point']])\n",
    "    Label2=np.column_stack([df['humidity'], df['dew_point']])\n",
    "    Label3=np.column_stack([df['uv_idx'], df['elevation']])\n",
    "    Label4=np.column_stack([df['temp'], df['humidity']])\n",
    "    Label5=np.column_stack([df['vis'], df['ground_press']])\n",
    "    Label6=np.column_stack([df['wind_dir'], df['wind_speed']])\n",
    "    Label7=np.column_stack([df['elevation'], df['temp']])\n",
    "\n",
    "    pca=PCA(n_components=1)   \n",
    "\n",
    "    pca_value_1=pca.fit_transform(Label1)\n",
    "    pca_value_2=pca.fit_transform(Label2)\n",
    "    pca_value_3=pca.fit_transform(Label3)\n",
    "    pca_value_4=pca.fit_transform(Label4)\n",
    "    pca_value_5=pca.fit_transform(Label5)\n",
    "    pca_value_6=pca.fit_transform(Label6)\n",
    "    pca_value_7=pca.fit_transform(Label7)\n",
    "\n",
    "    inputs=np.column_stack([df['time'], pca_value_1,pca_value_2,pca_value_3,pca_value_4,pca_value_5, pca_value_6, pca_value_7, df['azimuth']])\n",
    "    pca_df = pd.DataFrame(inputs)\n",
    "    pca_df.columns = ['time', 'variable1', 'variable2', 'variable3', 'variable4', 'variable5', 'variable6', 'variable7','azimuth']\n",
    "    pca_feature = [ 'variable1', 'variable2', 'variable3', 'variable4', 'variable5', 'variable6', 'variable7', 'azimuth']\n",
    "    ###########\n",
    "    time_periods = {\n",
    "        \"1시~6시\": (1, 2, 3, 4, 5, 6),\n",
    "        \"7시~9시\": (7, 8, 9),\n",
    "        \"10시~12시\": (10, 11, 12),\n",
    "        \"13시~15시\": (13, 14, 15),\n",
    "        \"16시~19시\": (16, 17, 18, 19),\n",
    "        \"20시~0시\": (20, 21, 22, 23, 0) \n",
    "    }\n",
    "\n",
    "\n",
    "    hourly_data = {time_period: pd.DataFrame() for time_period in time_periods}\n",
    "\n",
    "    for time_period, hours in time_periods.items():\n",
    "        data_period = pca_df[pca_df['time'].dt.hour.isin(hours)]\n",
    "        hourly_data[time_period] = data_period\n",
    "\n",
    "    #print(hourly_data)#######\n",
    "\n",
    "\n",
    "    # 군집화를 위한 K-Means 모델 파라미터 설정\n",
    "    n_clusters = 5  \n",
    "\n",
    "    # 시간대별로 군집화 레이블 생성\n",
    "    cluster_labels = {}\n",
    "    inertia_values = {}\n",
    "    for time_period, data_period in hourly_data.items():\n",
    "        if len(data_period) >= 5:  # 5개 이상의 데이터가 있는 시간대만 처리\n",
    "            # 변수 선택 (variable1부터 variable7까지 사용)\n",
    "            features = data_period[pca_feature]\n",
    "\n",
    "            # K-Means 모델 초기화 및 학습\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=0)  ## TimeSeriesKMeans?\n",
    "            labels = kmeans.fit_predict(features)\n",
    "\n",
    "            # 군집화 레이블을 시간대별로 저장\n",
    "            cluster_labels[time_period] = labels\n",
    "\n",
    "        else:\n",
    "            print(f\"Skipping time period {time_period} due to insufficient data points.\")\n",
    "\n",
    "\n",
    "    updated_labels = {}\n",
    "    for hour, labels in cluster_labels.items():\n",
    "        updated_labels[hour] = [f'{hour}_{label}' for label in labels]\n",
    "    ##print(updated_labels)#####\n",
    "\n",
    "    for time_period, labels in updated_labels.items():\n",
    "        data_period = df[df['time'].dt.hour.isin(time_periods[time_period])]\n",
    "\n",
    "        data_period['cluster_label'] = labels\n",
    "\n",
    "        df.loc[data_period.index, 'cluster_label'] = data_period['cluster_label']\n",
    "\n",
    "    #print(df)######\n",
    "\n",
    "    ############# api 나누기\n",
    "    api_data = df[-24:]\n",
    "    row_data = df[:-24]\n",
    "\n",
    "    time_periods = {\n",
    "        \"1시~6시\": (1, 2, 3, 4, 5, 6),\n",
    "        \"7시~9시\": (7, 8, 9),\n",
    "        \"10시~12시\": (10, 11, 12),\n",
    "        \"13시~15시\": (13, 14, 15),\n",
    "        \"16시~19시\": (16, 17, 18, 19),\n",
    "        \"20시~0시\": (20, 21, 22, 23, 0) \n",
    "    }\n",
    "\n",
    "\n",
    "    hourly_data = {time_period: pd.DataFrame() for time_period in time_periods}\n",
    "\n",
    "    for time_period, hours in time_periods.items():\n",
    "        data_period = df[df['time'].dt.hour.isin(hours)]\n",
    "        hourly_data[time_period] = data_period\n",
    "\n",
    "\n",
    "\n",
    "    params_list = []\n",
    "    predict_list = []\n",
    "    skipped_clusters = 0  # 클러스터가 건너뛰어진 횟수를 추적하는 변수\n",
    "    hourmean_list = []\n",
    "\n",
    "    for time_period, hours in time_periods.items():\n",
    "        print('Time Period: {}'.format(time_period))\n",
    "        data_period = df[df['time'].dt.hour.isin(hours)]\n",
    "        hourly_data[time_period] = data_period\n",
    "\n",
    "        for i in range(0, n_clusters):\n",
    "            col_list = ['model1', 'model2', 'model3', 'model4', 'model5', 'pred_mean','cloud', \n",
    "                    'temp', 'humidity', 'ground_press', 'wind_speed',\n",
    "                   'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "                   'elevation',  'azimuth']\n",
    "            print('Cluster {} OLS'.format(i+1))\n",
    "            cluster_data = row_data[row_data['cluster_label'] == f'{time_period}_{i}']\n",
    "            if cluster_data.empty:\n",
    "                skipped_clusters += 1\n",
    "                print(f\"Cluster {i+1} for Time Period {time_period} has insufficient data. Using zero values.\")\n",
    "                X = [[0]*len(col_list)]\n",
    "                y = [0]\n",
    "            else:\n",
    "                X = cluster_data[col_list]\n",
    "                y = cluster_data['real']\n",
    "\n",
    "\n",
    "            test = api_data[(api_data['cluster_label'] == f'{time_period}_{i}') & (api_data['time'].dt.hour.isin(hours))]\n",
    "            if test.empty:\n",
    "                print(f\"Skipping Cluster {i+1} due to insufficient data.\")\n",
    "                continue          \n",
    "            pipe = Pipeline([\n",
    "                    ('voting', VotingRegressor([\n",
    "                    ('RandomForest', RandomForestRegressor(random_state=42)),\n",
    "                    ('Lasso', Lasso(alpha=10, max_iter=500, random_state=42)),\n",
    "                    ('Huber', HuberRegressor())\n",
    "                    ]))\n",
    "                ])\n",
    "\n",
    "\n",
    "            pipe.fit(X,y)\n",
    "\n",
    "            # Predict for new data points with the same cluster label\n",
    "            api_test = test[col_list]\n",
    "            prediction = pipe.predict(api_test)\n",
    "\n",
    "            pred_df = pd.DataFrame(prediction, columns=['predicted_amount'])\n",
    "            pred_df['time'] = list(test['time'])\n",
    "            predict_list.append(pred_df)\n",
    "\n",
    "    print(f\"Total clusters skipped: {skipped_clusters}\")\n",
    "    print(\"\")\n",
    "\n",
    "    prediction_df = pd.concat(predict_list).sort_values('time')\n",
    "    prediction_df.columns = ['pred','time']\n",
    "    prediction_df = prediction_df.reset_index(drop=True)\n",
    "    print(prediction_df)\n",
    "\n",
    "\n",
    "\n",
    "#         submit = list(prediction_df['pred'])\n",
    "    pred_result_list.append(prediction_df)\n",
    "#         print(fcst_combined)\n",
    "    return pred_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#주최측 제공 Metric\n",
    "def calc_profit(actual_gens, forecast_gens):\n",
    "    CAPACITY = 99.0\n",
    "    facility_utilization_rate = [actual / CAPACITY for actual in actual_gens]\n",
    "\n",
    "    filter_facility_utilization_rate = [\n",
    "        utilization >= 0.1 for utilization in facility_utilization_rate\n",
    "    ]\n",
    "\n",
    "    errors = [\n",
    "        abs(forecast - actual) / CAPACITY * 100\n",
    "        for forecast, actual in zip(forecast_gens, actual_gens)\n",
    "    ]\n",
    "\n",
    "    target_errors = [\n",
    "        error\n",
    "        for error, is_filtered in zip(errors, filter_facility_utilization_rate)\n",
    "        if is_filtered\n",
    "    ]\n",
    "    target_actual_gens = [\n",
    "        actual\n",
    "        for actual, is_filtered in zip(\n",
    "            actual_gens, filter_facility_utilization_rate\n",
    "        )\n",
    "        if is_filtered\n",
    "    ]\n",
    "\n",
    "    profits = [0] * len(target_actual_gens)\n",
    "\n",
    "    for i, error in enumerate(target_errors):\n",
    "        if error <= 6:\n",
    "            profits[i] = target_actual_gens[i] * 4\n",
    "        elif 6 < error <= 8:\n",
    "            profits[i] = target_actual_gens[i] * 3\n",
    "    \n",
    "    return profits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Period: 1시~6시\n",
      "Cluster 1 OLS\n",
      "Skipping Cluster 1 due to insufficient data.\n",
      "Cluster 2 OLS\n",
      "Skipping Cluster 2 due to insufficient data.\n",
      "Cluster 3 OLS\n",
      "Skipping Cluster 3 due to insufficient data.\n",
      "Cluster 4 OLS\n",
      "Skipping Cluster 4 due to insufficient data.\n",
      "Cluster 5 OLS\n",
      "Time Period: 7시~9시\n",
      "Cluster 1 OLS\n",
      "Skipping Cluster 1 due to insufficient data.\n",
      "Cluster 2 OLS\n",
      "Skipping Cluster 2 due to insufficient data.\n",
      "Cluster 3 OLS\n",
      "Cluster 4 OLS\n",
      "Skipping Cluster 4 due to insufficient data.\n",
      "Cluster 5 OLS\n",
      "Skipping Cluster 5 due to insufficient data.\n",
      "Time Period: 10시~12시\n",
      "Cluster 1 OLS\n",
      "Skipping Cluster 1 due to insufficient data.\n",
      "Cluster 2 OLS\n",
      "Skipping Cluster 2 due to insufficient data.\n",
      "Cluster 3 OLS\n",
      "Skipping Cluster 3 due to insufficient data.\n",
      "Cluster 4 OLS\n",
      "Cluster 5 OLS\n",
      "Skipping Cluster 5 due to insufficient data.\n",
      "Time Period: 13시~15시\n",
      "Cluster 1 OLS\n",
      "Skipping Cluster 1 due to insufficient data.\n",
      "Cluster 2 OLS\n",
      "Skipping Cluster 2 due to insufficient data.\n",
      "Cluster 3 OLS\n",
      "Cluster 4 OLS\n",
      "Skipping Cluster 4 due to insufficient data.\n",
      "Cluster 5 OLS\n",
      "Skipping Cluster 5 due to insufficient data.\n",
      "Time Period: 16시~19시\n",
      "Cluster 1 OLS\n",
      "Skipping Cluster 1 due to insufficient data.\n",
      "Cluster 2 OLS\n",
      "Skipping Cluster 2 due to insufficient data.\n",
      "Cluster 3 OLS\n",
      "Skipping Cluster 3 due to insufficient data.\n",
      "Cluster 4 OLS\n",
      "Cluster 5 OLS\n",
      "Skipping Cluster 5 due to insufficient data.\n",
      "Time Period: 20시~0시\n",
      "Cluster 1 OLS\n",
      "Skipping Cluster 1 due to insufficient data.\n",
      "Cluster 2 OLS\n",
      "Skipping Cluster 2 due to insufficient data.\n",
      "Cluster 3 OLS\n",
      "Skipping Cluster 3 due to insufficient data.\n",
      "Cluster 4 OLS\n",
      "Cluster 5 OLS\n",
      "Skipping Cluster 5 due to insufficient data.\n",
      "Total clusters skipped: 0\n",
      "\n",
      "         pred                      time\n",
      "0    0.000000 2023-11-15 01:00:00+09:00\n",
      "1    0.000000 2023-11-15 02:00:00+09:00\n",
      "2    0.000000 2023-11-15 03:00:00+09:00\n",
      "3    0.000000 2023-11-15 04:00:00+09:00\n",
      "4    0.000000 2023-11-15 05:00:00+09:00\n",
      "5    0.000000 2023-11-15 06:00:00+09:00\n",
      "6    0.300633 2023-11-15 07:00:00+09:00\n",
      "7    3.662364 2023-11-15 08:00:00+09:00\n",
      "8   23.949777 2023-11-15 09:00:00+09:00\n",
      "9   48.393942 2023-11-15 10:00:00+09:00\n",
      "10  65.949732 2023-11-15 11:00:00+09:00\n",
      "11  74.722881 2023-11-15 12:00:00+09:00\n",
      "12  73.667839 2023-11-15 13:00:00+09:00\n",
      "13  65.852516 2023-11-15 14:00:00+09:00\n",
      "14  57.915528 2023-11-15 15:00:00+09:00\n",
      "15  40.617545 2023-11-15 16:00:00+09:00\n",
      "16  15.723751 2023-11-15 17:00:00+09:00\n",
      "17   1.498997 2023-11-15 18:00:00+09:00\n",
      "18  -0.339876 2023-11-15 19:00:00+09:00\n",
      "19   0.002711 2023-11-15 20:00:00+09:00\n",
      "20   0.002711 2023-11-15 21:00:00+09:00\n",
      "21   0.002711 2023-11-15 22:00:00+09:00\n",
      "22   0.002711 2023-11-15 23:00:00+09:00\n",
      "23   0.002711 2023-11-16 00:00:00+09:00\n"
     ]
    }
   ],
   "source": [
    "date = '2023-11-15'\n",
    "a = making_predict(round1_, 1, date)\n",
    "round_result = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = list(round_result['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.30063269808393006,\n",
       " 3.662364481107792,\n",
       " 23.949776881015016,\n",
       " 48.39394210340354,\n",
       " 65.94973166055641,\n",
       " 74.7228814199007,\n",
       " 73.66783946152566,\n",
       " 65.85251623250582,\n",
       " 57.9155283441624,\n",
       " 40.617545053898475,\n",
       " 15.723750924256143,\n",
       " 1.4989965588920489,\n",
       " -0.3398759192545813,\n",
       " 0.00271110576542692,\n",
       " 0.0027111057434557,\n",
       " 0.0027111056701697583,\n",
       " 0.0027111056756613777,\n",
       " 0.002711105773940531]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# amounts = prediction\n",
    "# API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJTZ3FicHhyZVVMaGRtaWVuU1JxWWl4IiwiaWF0IjoxNjk4ODk2MTYxLCJleHAiOjE3MDAyMzMyMDAsInR5cGUiOiJhcGlfa2V5In0.I9OvmWqhDhf3ePv8t-hFFWwGCokcSbK7e8-fJfIZ5lU\"\n",
    "# success = requests.post(f'https://research-api.solarkim.com/cmpt-2023/bids', data=json.dumps(amounts), headers={\n",
    "#                             'Authorization': f'Bearer {API_KEY}'\n",
    "#                         }).json()\n",
    "# print(success)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
